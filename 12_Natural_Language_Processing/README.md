# Определение токсичных комментариев

## Описание проекта

Цель проекта - предложить модель, которая сможет определять токсичные комментарии до их размещения на сайте. Использованные данные - размеченный корпус комментариев с английской Википедии.

## Осуществленные операции

* Препроцессинг данных: удаление лишней информации из корпуса.

* Лемматизация и векторизация текстов.

* Поиск оптимальной модели: обучение нескольких моделей с подбором гиперпараметров и кросс-валидацией.

* Попытка донастройки предобученного BERT: векторизация текстов, построение эмбеддингов.

* Выбор оптимальной модели, проверка ее на тестовой выборке.

## Использованные инструменты, методики

* pandas
* регулярные выражения
* nltk
* sklearn
* transformers
* BERT

## Дальнейшие действия

Заставить предобученную модель BERT во время выполнения проекта не удалось, судя по всему из-за конфликта версий tensorflow. Поэтому, планирую все-таки заставить BERT заработать, вероятно, попробовав его запустить в другой среде с другой версией tensorflow. Это должно увеличить точность модели.
